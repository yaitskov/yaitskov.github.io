<!doctype html>
<html lang="en">
    <head>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-CBWXWH01ZL"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-CBWXWH01ZL');
        </script>

        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>DNN to SQL translation</title>
        <link rel="stylesheet" href="../css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../">Daniil Iaitskov Blog</a>
            </div>
            <nav>
              <a href="../index.html">Home</a>
              <a href="../about.html">About</a>
              <a href="../contact.html">Contact</a>
            </nav>
        </header>

        <main role="main">
            <h1>DNN to SQL translation</h1>
            <article>
    <section class="header">
        Posted on April 12, 2023
        
    </section>
    <section>
        <p>AI becomes more and more accessible technology as time goes. The
topic in this blog post reminds me about the DOOM engineering
challenge, when the popular FPS game is ported to all kinds of
hardware (ATMs, oscilloscopes, DSLR etc), because the post shows a way
to translate DNN, trained in PyTorch framework, into an SQL query.</p>
<p>The idea to use DNN in SQL came out as a solution for the problem of
classification text fields with high cardinality, such as mail
address, into a few categories for building histograms, during
exploratory data analysis in <a href="https://www.napkin.run/">napkin</a>
tool. With DNN in the form of SQL predicate there is no need to take
data out of DB.</p>
<h2 id="training-and-preparing-dnn-model">Training and preparing DNN model</h2>
<p>Let’s borrow NN, trained in <a href="https://machinelearningmastery.com/creating-a-training-loop-for-pytorch-models/">pima indian
diabetes</a>
example for PyTorch. It is a simple NN with a few dense layers and
ReLU/Sigmoid activation functions.</p>
<p>The PyTorch model has following structure:</p>
<pre><code>model = nn.Sequential(
  nn.Linear(8, l1outs),
  nn.ReLU(),
  nn.Linear(l1outs, l2outs),
  nn.ReLU(),
  nn.Linear(l2outs, 1),
  nn.Sigmoid())</code></pre>
<p>Weights of the trained model need to be extracted. PyTorch can persist
the model as a binary file, but napkin is written in Haskell. So a
conversion step is required. Export model weights into a JSON file:</p>
<pre><code>from torch.utils.data import Dataset
from json import JSONEncoder

class EncodeTensor(JSONEncoder,Dataset):
  def default(self, obj):
    if isinstance(obj, torch.Tensor):
      return obj.cpu().detach().numpy().tolist()
    return super(NpEncoder, self).default(obj)

… model training

with open(“weights.json”, “w”) as mfh:
  json.dump(model.state_dict(), mfh, cls=EncodeTensor)</code></pre>
<p><em>weighs.json</em> has weights and biases, but activation functions are missing.</p>
<h4 id="file-insertactivationfunctions.hs">File <em>InsertActivationFunctions.hs:</em></h4>
<pre><code>#! /usr/bin/env nix-shell
#! nix-shell -i runghc -p &quot;ghc.withPackages (ps:[ps.aeson ps.bytestring ps.vector])&quot;

{-# LANGUAGE OverloadedStrings #-}
{-# LANGUAGE ScopedTypeVariables #-}

import Data.Aeson as A
import Data.Aeson.Key as A
import Data.Aeson.KeyMap as A
import Data.Bits (shiftL)
import Data.ByteString.Lazy as BSL
import Data.Maybe
import Data.Text as T
import Data.Vector as V
import Prelude
import System.Environment (getArgs)

include :: [Text] -&gt; Value -&gt; Value
include aFuns (Object weights) = go aFuns 0 []
  where
    layerIndex i
      | i == (0 :: Int) = A.fromText &quot;0&quot;
      | otherwise = A.fromText . T.pack . show $ (1 :: Int) `shiftL` i

    lookupWeights i = A.lookup (layerIndex i &lt;&gt; &quot;.weight&quot;) weights
    go [] iLayer dnnLayers =
      case lookupWeights iLayer of
        Nothing -&gt; Array . V.fromList . fmap Object $ Prelude.reverse dnnLayers
        Just _ -&gt; error $ &quot;Number of layers is more than activation functions&quot;
    go (af:afs) iLayer dnnLayers =
      case lookupWeights iLayer of
        Nothing -&gt; error $ &quot;Number of layers is less than activation functions&quot;
        Just weightMatrix -&gt;
          let nl = A.fromList [
                                (&quot;weights&quot;, weightMatrix),
                                (&quot;biases&quot;, fromJust $ A.lookup (layerIndex iLayer &lt;&gt; &quot;.bias&quot;) weights),
                                (&quot;activation&quot;, String af)
                               ]
          in go afs (iLayer + 1) (nl:dnnLayers)

main :: IO ()
main = do
  aFuns &lt;- getArgs
  layers &lt;- fromJust . A.decode' &lt;$&gt; BSL.readFile &quot;weights.json&quot;
  A.encodeFile &quot;model.json&quot; (include (fmap T.pack aFuns) layers)</code></pre>
<p>Run the script:</p>
<pre><code>$ chmod +x ./InsertActivationFunctions.hs &amp;&amp; \
  ./InsertActivationFunctions.hs ReLU ReLU Sigmoid</code></pre>
<p>File <em>model.json</em> describes the whole NN and it is ready to be included into a napkin spec.</p>
<h2 id="napkin-installation">Napkin installation</h2>
<p><a href="https://docs.napkin.run/install/">napkin</a> could be installed in
multiple ways. One of them is docker. DNN feature is not merged into
master, so a tag with commit must be specified.</p>
<pre><code>$ docker run --rm --pull=always soostone/napkin-exe:v0.5.14-63f5f2b8 \
  cat /bin/napkin-docker &gt; ./napkin-docker &amp;&amp; chmod +x ./napkin-docker</code></pre>
<p>napkin needs a spec file to run. The spec YAML file describes SQL
queries, database to work with, etc.</p>
<h4 id="file-spec.yaml">File <em>spec.yaml</em>:</h4>
<p>BigQuery and Posgres backends are supported by the feature. The spec
below is for BigQuery. Some observatoins data are already inlined into
the spec as a literal query <em>pima_observations</em>.</p>
<pre><code>app_name: Classifies rows with embedded DNN
db_url: bigquery://bigquery.googleapis.com/project
backend: BigQuery
parser_dialect: napkin.bigquery
preprocessors:
  - bigquery_defaults:
      dataset: dnn_dataset
  - define_dnn_macros:
      dnns:
        pima: model.json

tables:
  pima_accuracy75:
    create_action:
      sql_query:
        query: |
          select errors, total, errors / total as ration from
            (select
              (select count(*) from pima_false_positive)
              + (select count(*) from pima_true_negative) as errors,
              (select count(*) from pima_observations) as total) as x

    post_hooks:
      - assert_expression:
          expression: 1.0 * errors / total &lt; 0.26

  pima_false_positive:
    create_action:
      sql_query:
        query: |
          select * from pima_positively_classified_by_dnn where expected_class &lt; 1
    post_hooks:
      - assert_expression:
          expression: count(*) &gt; 0
  pima_true_negative:
    create_action:
      sql_query:
        query: |
          select * from pima_negatively_classified_by_dnn where expected_class &gt; 0
    post_hooks:
      - assert_expression:
          expression: count(*) &gt; 0
  pima_positively_classified_by_dnn:
    create_action:
      sql_query:
        query: |
          select * from pima_observations
          where pima(pregnant, glucose, pressure, skin,
                     insulin, bmi, pedigree, age)[offset(0)] &gt; 0.5
  pima_negatively_classified_by_dnn:
    create_action:
      sql_query:
        query: |
          select * from pima_observations
          where pima(pregnant, glucose, pressure, skin,
                     insulin, bmi, pedigree, age)[offset(0)] &lt; 0.5
  pima_observations:
    create_action:
      sql_query:
        # pregnant,  glucose, skin, insulin, bmi, pedigree, age
        query: |
          select rs[offset(0)] as pregnant,
                 rs[offset(1)] as glucose,
                 rs[offset(2)] as pressure,
                 rs[offset(3)] as skin,
                 rs[offset(4)] as insulin,
                 rs[offset(5)] as bmi,
                 rs[offset(6)] as pedigree,
                 rs[offset(7)] as age,
                 rs[offset(8)] as expected_class
          from unnest([ struct(6,148,72,35,0,33.6,0.627,50,1),
                        struct(1,85,66,29,0,26.6,0.351,31,0),
                        struct(8,183,64,0,0,23.3,0.672,32,1),
                        struct(1,89,66,23,94,28.1,0.167,21,0),
                        struct(0,137,40,35,168,43.1,2.288,33,1),
                        struct(5,116,74,0,0,25.6,0.201,30,0),
                        struct(3,78,50,32,88,31.0,0.248,26,1),
                        struct(10,115,0,0,0,35.3,0.134,29,0),
                        struct(2,197,70,45,543,30.5,0.158,53,1)]) as rs</code></pre>
<p>spec.yaml binds the model.json to <em>pima</em> macro, which is expanded as
an SQL subquery. You can check it via dump command, producing SQL
ready to be fed into a database. Dump command doesn’t require access
to BigQuery.</p>
<pre><code>$ ./napkin-docker dump -s spec.yaml</code></pre>
<p>The query containing NN is located in file <em>./dump/napkin_devel.pima_positively_classified_by_dnn/1.sql</em></p>
<pre><code>SELECT *
FROM `dnn_dataset`.pima_observations AS pima_observations
WHERE ((SELECT
          ARRAY_AGG((1 / (1 + EXP((0 - (((`w`[OFFSET(0)] + (`w`[OFFSET(1)] * `l1out`[OFFSET(0)])) + (`w`[OFFSET(2)] * `l1out`[OFFSET(1)])) + (`w`[OFFSET(3)] * `l1out`[OFFSET(2)]))))))) AS `nnOut`
        FROM UNNEST([struct(-1.4292612075805664, 0.46713218092918396, 0.31342944502830505, 8.353928476572037e-2)]) AS `w`
        CROSS JOIN (SELECT
                      ARRAY_AGG(GREATEST(0,
                                         (((((`w`[OFFSET(0)] + (`w`[OFFSET(1)] * `l0out`[OFFSET(0)])) + (`w`[OFFSET(2)] * `l0out`[OFFSET(1)])) + (`w`[OFFSET(3)] * `l0out`[OFFSET(2)])) + (`w`[OFFSET(4)] * `l0out`[OFFSET(3)])) + (`w`[OFFSET(5)] * `l0out`[OFFSET(4)])))) AS `l1out`
                    FROM UNNEST([struct(-0.41208043694496155, 0.2061747908592224, -0.16841396689414978, 0.2145361751317978, 0.3863857090473175, 2.057105116546154e-2), struct(-0.8970054984092712, -0.11880557984113693, 0.4053782522678375, -1.4171559363603592e-2, -8.417066186666489e-2, -0.984534740447998), struct(-7.326607406139374e-2, 8.147265017032623e-2, -0.4211576282978058, 0.2435821145772934, -0.4402327537536621, 2.4828349705785513e-3)]) AS `w`
                    CROSS JOIN (SELECT
                                  ARRAY_AGG(GREATEST(0,
                                                     ((((((((`w`[OFFSET(0)] + (`w`[OFFSET(1)] * pregnant)) + (`w`[OFFSET(2)] * glucose)) + (`w`[OFFSET(3)] * pressure)) + (`w`[OFFSET(4)] * skin)) + (`w`[OFFSET(5)] * insulin)) + (`w`[OFFSET(6)] * bmi)) + (`w`[OFFSET(7)] * pedigree)) + (`w`[OFFSET(8)] * age)))) AS `l0out`
                                FROM UNNEST([struct(0.11652952432632446, -0.1514103263616562, -0.2902229130268097, -0.25702202320098877, -0.30213668942451477, 0.15019038319587708, -8.555655926465988e-2, 0.2731674313545227, 2.377433329820633e-2), struct(-0.8223007917404175, 1.0374555587768555, 0.22740879654884338, -0.34332337975502014, 1.0697017423808575e-2, -8.385843830183148e-4, -1.5387434512376785e-2, 0.23497509956359863, 7.723002135753632e-2), struct(-0.12624654173851013, -0.3030771315097809, -0.21591763198375702, 0.26572340726852417, -0.23025500774383545, -0.15994291007518768, -0.2668708860874176, 3.350885212421417e-2, -0.33851397037506104), struct(0.2801574766635895, -0.3144024610519409, -0.21931664645671844, 8.408840000629425e-2, -3.6737680435180664e-2, -0.14777924120426178, -0.32633376121520996, -0.26817217469215393, 0.20330695807933807), struct(0.23825359344482422, 0.5980736613273621, -1.4002146199345589e-2, -0.255145400762558, -0.32139626145362854, -1.51359923183918e-2, -0.31143277883529663, 5.861988756805658e-4, 0.5181198120117188)]) AS `w`) AS `l1`) AS `l2`)[OFFSET(0)] &gt; 0.5)</code></pre>
<p>Until NN is trained with <em>Double</em> weights, using BigQuey is less
efficient, because there is no Float32 nor Float16 types. I hope the
dot operator will appear in SQL dialects to make NN more practical approach.</p>
<p><a href="mailto:daniil.iaitskov@soostone.com" class="email">daniil.iaitskov@soostone.com</a></p>
    </section>
</article>

        </main>

        <footer>
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </footer>
    </body>
</html>
